# Apache Spark Study

## 아파치 스파크 정의

- 빅데이터 처리를 위한 오픈소스 병렬분산처리 플랫폼
  대량의 데이터를 고속 병렬분산처리하며 스토리지 I/O와 네트워크 I/O를 최소화하도록 처리함
- 복수의 컴포넌트로 구성되며 스파크 코어를 중심으로 스파크 SQL, 스파크 스트리밍, MLlib, 그래프X 등 여러 라이브러리 제공
- HDFS, 하이브, HBase, PostgreSQL, MySQL, CSV 등 여러 데이터 소스로부터 소싱 가능
- 동일한 데이터에 변환처리가 연속으로 이루어지는 경우에 적합

## 스파크의 특징

- 반복처리와 연속으로 이루어지는 변환처리의 고속화
    - 데이터를 스토리지에 저장하는 맵리듀스를 반복처리에 사용 시 매번 불필요한 디스크와 네트워크 I/O가 발생하여 오버헤드 발생
    - 데이터를 메모리에서 처리하는 스파크는 이러한 단점을 커버
    - 단, 한 번만 실행되는 변환처리와 추출/가공처리에서는 큰 이득이 없음
- 시행착오에 적합한 환경 제공
    - 한 대의 머신으로 처리할 수 있는 용량보다 더 큰 데이터셋을 병렬 분산 환경 의식 없이 다룰 수 있음
- 서로 다른 처리를 통합해 이용할 수 있는 환경
    - 배치처리, 스트림처리, SQL 처리 등을 하나의 미들웨어로 통합하여 사용이 가능해 운용부담을 줄일 수 있음

## 스파크 분산처리 환경

스파크는 세 종류의 클러스터 관리 시스템을 지원

- YARN
- Mesos
- Spark Standalone

클러스터 관리 시스템 하에서 각 머신은 마스터 노드 또는 워커 노드로 동작

분산처리는 아래와 같은 순서로 이루어짐

1) 애플리케이션 배포 및 계산 리소스 요구

2) 클러스터 내 계산 리소스 확보

3) 드라이버 프로그램 구동

4) 태스크 스케줄링 및 실행

### 애플리케이션 배포 및 계산 리소스 요구

클라이언트가 스파크 애플리케이션을 클러스터에 배포함과 동시에 executor의 스펙을 지정 (CPU 코어 수 및 메모리 할당량, executor의 수)

### 클러스터 내 계산 리소스 확보

마스터 노드가 각 워커 노드의 이용 가능한 리소스양과 executor 스펙을 고려하여 워커 노드에 구동을 요청

### 드라이버 프로그램 구동

스파크 애플리케이션의 엔트리 포인트가 되는 프로그램

사용자가 드라이버 프로그램에 RDD의 생성과 변환, 액션의 로직 등을 기술

RDD라는 분산 컬렉션과 지연 평가(lazy evaluation)에 의해 사용자는 대량의 데이터를 평소 다루던 컬렉션처럼 기술할 수 있게됨

### 태스크 스케줄링 및 실행

RDD 생성부터 액션 적용까지를 통틀어 잡이라는 단위로 처리

잡은 스케줄러에 의해 executor가 처리 가능한 태스크라는 단위로 분할 (태스크는 파티션 단위로 데이터를 로드하고 변환과 액션을 적용하는 처리 단위)

스케줄러는 데이터 지역성 등을 고려해 네트워크 통신과 I/O 부하가 작아지도록 최적화하여 태스크를 구성

## 스파크 작동 환경

| 호스트명 | 역할 | 설명 |
| --- | --- | --- |
| spark-client | 클라이언트 | 애플리케이션을 구동하는 클라이언트 (단일 머신 환경에서는 이 호스트만을 이용) |
| spark-master | 마스터 노드 | 클러스터 내의 리소스를 집중 관리 |
| spark-worker | 워커 노드 | CPU 코어와 메모리 등 애플리케이션 실행에 필요한 리소스를 제공 |

## HDFS

하둡 파일 분산시스템으로, 클러스터 환경에서의 작동을 전제로 설계

파일을 블록 단위로 분할하여 분산해 저장함으로써 거대한 데이터를 보존할 수 있고 높은 I/O 처리량을 실현할 수 있음

- NameNode (마스터 노드): 파일의 메타데이터와 보존된 파일의 분할된 조각이 어떤 DataNode에서 관리되는지 등의 정보를 관리
- DataNode (워커 노드): HDFS상의 보존된 파일의 블록을 관리

## YARN

하둡의 클러스터 관리 시스템으로 스파크를 포함한 각종 분산처리 애플리케이션이 작동하는 환경을 제공하는 시스템

- ResourceManager (마스터 노드): 클러스터 전체의 계산 리소스를 관리하고, 클라이언트가 요구한 리소스를 NodeManager로부터 확보하도록 스케줄링
- NodeManager (워커 노드): ResourceManager로부터 받은 요청에 따라 자신의 리소스만 관리. 필요한 계산 리소스를 확보한 컨테이너 위에서 분산 처리를 수행

## RDD

- 스파크의 기본 자료구조로서 RDD를 가공해 새로운 RDD를 만들기를 반복하여 사용함
- 분산처리를 전제로 설계됨. 파티션 단위로 나뉘어 여러 머신에서 처리함

RDD에는 변환과 액션 두 종류의 처리를 적용할 수 있음

### 변환(Trasformation)

RDD를 가공하고 새로운 RDD를 얻는 처리

- filter: 요소를 필터링
- map: 각 요소에 동일한 처리를 적용 (ex. 송이버섯 → 버섯, 마늘 → 야채)
- flatmap: 각 요소에 동일한 처리를 적용하고 여러 개의 요소를 생성 (ex. This is a pen → This, is, a, pen)
- zip: 두 RDD를 조합해 key-value pair 생성
- reduceByKey: 같은 키를 가지는 요소를 집약처리
- join: 두 개의 RDD에서 같은 키를 가지는 요소끼리 조인

### 액션(Action)

RDD 내용을 바탕으로 데이터를 가공하지 않고 원하는 결과를 얻는 조작

- saveAsTextFile: RDD의 내용을 파일로 출력
- count: RDD의 요소 수를 카운트

### RDD 영속화

RDD 영속화 조건

- 셔플이 발생하는 변환을 실행하기 직전의 RDD
- 사용자에 의해서 명시적으로 영속화가 선언된 RDD

만약 RDD의 파티션이 하나라도 영속화되지 않으면 해당 RDD 전체가 영속화되지 않은 것으로 간주되고 RDD를 재사용하는 경우에 해당 태스크를 다시 한번 스케줄링 해야하기 때문에 비효율적

RDD의 파티션이 전부 영속화되면 RDD 자체가 영속화된 것으로 간주하고 해당 데이터를 로드하기 위한 처리를 생략할 수 있음

## DataFrame

- 스파크 SQL이 DataFrame을 다뤄 데이터를 처리
- JSON, Parquet, 하이브 호환테이블 등 각종 데이터셋과 RDD로부터도 DataFrame 생성 가능
- RDD에 실제 데이터가 들어있지 않는 것처럼 DataFrame에도 실제 데이터가 들어있지 않고 실제로는 스키마 정보, 논리 플랜 등이 들어 있음

### DataFrame API

- 간결하고 가독성 높은 코드로 데이터처리 기술
    - 구조화되어 있으며 스키마 정보가 주워져 컬럼명으로 데이터에 접근 가능
    - RDD 처리를 기술할 때보다 코드가 간결하고 가독성이 높음
- 옵티마이저에 의한 최적화
    - RDD 처리로 변환되는 과정에 옵티마이저가 최적화를 진행
    - 효율이 좋아지게 처리순서를 변환하여 논리 플랜을 최적화
    - 처리 대상의 읽어 들이는 데이터 범위를 줄여 물리 플랜을 최적화 (ex. 파티셔닝된 데이터셋)

## 스파크 SQL

- 구조화된 데이터셋을 간단하고 효율적으로 다루는 수단
- JSON, Parquet, ORC, JDBC 지원 테이블, 하이브 호환 테이블, 스파크 SQL 전용 테이블 등의 데이터셋 지원
- 데이터셋으로부터 다음과 같은 처리 가능
    - 조건에 맞는 데이터 추출
    - 특정한 이름으로 데이터 추출
    - 복수의 데이터셋 결합
    - 그룹 단위로 집약
    - 다른 형식의 구조화된 데이터셋으로 변한

## sbt

스칼라와 자바로 기술된 소스코드를 컴파일하고 라이브러리 의존 관계를 관리하는 등 빌드 프로세스 통합 관리 툴

sbt를 이용해 소스코드를 컴파일하고 JAR 파일로 패키징 하여 스파크 애플리케이션에 던져 줌

### 프로젝트 디렉토리 구조

sbt가 프로젝트 디렉토리 구조에 따라 소스코드가 있는 장소를 자동 인식

| 디렉토리 | 역할 |
| --- | --- |
| src/main/scala | 스칼라 소스코드 보관 |
| src/test/scala | 스칼라 테스트 코드 보관 |
| lib | 애플리케이션에 의존하는 라이브러리지만 sbt로 관리하지 않는 라이브러리 보관 |
| project | sbt 관련 설정 파일 보관 |

### 프로젝트 파일 구성

build.sbt 파일을 작성하여 빌드 정의

```scala
name := "spark-simple-app"
version := "0.1"
scalaVersion := "2.10.4"
libraryDependencies ++=
	Seq("org.apache.spark" % "spark-core_2.10" % "1.6.1" % "provided",
			"joda-time" % "joda-time" % "2.8.2")
			
assemblyOptions in assembly := (assemblyOption in assembly)
																.value.copy(includeScala = false)
```

- libraryDependencies에 sbt에 프로젝트가 의존하는 라이브러리를 Seq 형식으로 설정
- “<groupID>” % “<artifactID>” % “<version>” % “<configuration>” 형식으로 기술
- assemblyOptions in assembly는 sbt-assembly 플러그인을 위한 옵션 설정

빌드 정의가 완료되면 sbt 명령어로 JAR 파일을 만들고 스파크 애플리케이션에서 실행하면 됨

## 스파크 애플리케이션 실행

```bash
spark-submit \
--master <동작 모드> \
--class <main 메서드가 구현된 애플리케이션의 클래스> \
--name <애플리케이션 이름> \
<spark-submit 명령 옵션> \
애플리케이션 클래스가 포함된 JAR 파일 \
<애플리케이션에 넘기는 옵션>
```

### local 모드

spark-submit 명령을 실행한 클라이언트상에서 프로세스를 구동. 해당 프로세스 안에서 이그제큐터를 구동하여 애플리케이션을 실행함

master 옵션에 다음 중 하나를 선택하여 지정

- local: 이그제큐터에 한 개의 스레드만 할당
- local[*]: 클라이언트 머신에 탑재된 CPU 코어 수만큼 이그제큐터에 스레드를 할당
- local[<스레드개수>]: 이그제큐터에 지정된 수만큼의 스레드를 할당

### yarn-client 모드 / yarn-cluster 모드

YARN 클러스터 위에서 애플리케이션을 실행하는 모드

클러스터 노드 매니저상에서 이그제큐터가 동작하고 각 이그제큐터가 분산처리를 시행

- **yarn-client**는 드라이버 프로그램이 spark-submit을 실행한 클라이언트 호스트상에서 동작하여 디버깅이 간편
- **yarn-cluster**는 드라이버 프로그램이 클러스터의 NodeManager 상에서 동작하여 클러스터 전체의 리소스 이용 가능